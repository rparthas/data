{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d427fea2-91f5-4aff-a49e-74ffccc37e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c619911-5403-4fe7-a0c6-94e8a88cca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget https://github.com/alexeygrigorev/large-datasets/releases/download/dogs-cats/train.zip\n",
    "# os.mkdir(\"train\")\n",
    "# os.mkdir(\"validation\")\n",
    "# os.mkdir(\"train/cats\")\n",
    "# os.mkdir(\"validation/cats\")\n",
    "# os.mkdir(\"train/dogs\")\n",
    "# os.mkdir(\"validation/dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3784fde4-4f14-4932-8b0c-f5bc7d4f11de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10000):\n",
    "#     shutil.move(f\"source/cat.{i}.jpg\",f\"train/cats/cat.{i}.jpg\")\n",
    "#     shutil.move(f\"source/dog.{i}.jpg\",f\"train/dogs/dog.{i}.jpg\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dd92792-4aec-4371-b38b-81e5d16a6457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10000,12500):\n",
    "#     shutil.move(f\"source/cat.{i}.jpg\",f\"validation/cats/cat.{i}.jpg\")\n",
    "#     shutil.move(f\"source/dog.{i}.jpg\",f\"validation/dogs/dog.{i}.jpg\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8c963f3-6188-482e-ad5c-4bef7a194af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 175232)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "sgd = SGD(learning_rate=0.002, momentum=0.9)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aca031e8-d6cd-4b1b-bb78-9d5812670af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb3170b1-bec3-4abe-b0c3-fc8cc8cf980c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        'validation',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a5aa008-d48a-48a8-b7ee-948ce2f2219d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 20s 191ms/step - loss: 0.6988 - accuracy: 0.4840 - val_loss: 0.6930 - val_accuracy: 0.4880\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 18s 178ms/step - loss: 0.6929 - accuracy: 0.4980 - val_loss: 0.6929 - val_accuracy: 0.4880\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.6927 - accuracy: 0.5015 - val_loss: 0.6911 - val_accuracy: 0.5450\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 20s 198ms/step - loss: 0.6898 - accuracy: 0.5340 - val_loss: 0.6896 - val_accuracy: 0.5110\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 22s 222ms/step - loss: 0.6860 - accuracy: 0.5725 - val_loss: 0.6792 - val_accuracy: 0.5750\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 0.6823 - accuracy: 0.5600 - val_loss: 0.7163 - val_accuracy: 0.4970\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 0.6691 - accuracy: 0.5915 - val_loss: 0.6645 - val_accuracy: 0.5600\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 0.6665 - accuracy: 0.5895 - val_loss: 0.6609 - val_accuracy: 0.6540\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 22s 224ms/step - loss: 0.6609 - accuracy: 0.5815 - val_loss: 0.6692 - val_accuracy: 0.5740\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 0.6496 - accuracy: 0.6080 - val_loss: 0.6433 - val_accuracy: 0.6440\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "561ffb3e-37d5-42ad-a71a-409fc6adc82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5662499964237213"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f398aee0-cf3a-4b54-90c6-37a4ee3a8d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015473869860714017"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23cd175e-998a-422c-ba2e-5a5f5fac91fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a47346e-bfcf-4836-a981-a0fddcb08877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 0.6609 - accuracy: 0.6045 - val_loss: 0.6367 - val_accuracy: 0.6040\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 0.6447 - accuracy: 0.6245 - val_loss: 0.6204 - val_accuracy: 0.6670\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 0.6540 - accuracy: 0.6145 - val_loss: 0.6375 - val_accuracy: 0.6440\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 34s 337ms/step - loss: 0.6537 - accuracy: 0.6255 - val_loss: 0.6283 - val_accuracy: 0.6710\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 0.6492 - accuracy: 0.6195 - val_loss: 0.6283 - val_accuracy: 0.6650\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 31s 313ms/step - loss: 0.6510 - accuracy: 0.6250 - val_loss: 0.6234 - val_accuracy: 0.6430\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 31s 312ms/step - loss: 0.6464 - accuracy: 0.6260 - val_loss: 0.6145 - val_accuracy: 0.6740\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 0.6461 - accuracy: 0.6390 - val_loss: 0.6307 - val_accuracy: 0.6270\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 30s 296ms/step - loss: 0.6369 - accuracy: 0.6360 - val_loss: 0.6102 - val_accuracy: 0.6650\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 0.6487 - accuracy: 0.6325 - val_loss: 0.6011 - val_accuracy: 0.6940\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6310d93c-8973-429f-b2f3-3038470b6e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6231017351150513"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19b7ca01-8320-4593-946b-525385da1a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6606000065803528"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_accuracy'][5:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
